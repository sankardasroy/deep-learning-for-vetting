{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/my_test_model-1000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: %reset: not found\n",
      "yes: standard output: Broken pipe\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.12\n",
      "  latest version: 4.6.7\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "yes: standard output: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "! yes y | %reset\n",
    "! yes y |conda install -c conda-forge gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36088\n",
       "1    11963\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Use this cell later if you have to read test files form directory \n",
    "##Currently, don't use this , just load test fiels name directly from test.csv file\n",
    "def read_data(foldername):\n",
    "    filenames=[]\n",
    "    for fname in os.listdir(foldername):\n",
    "        filenames.append(fname)\n",
    "        \n",
    "    return filenames\n",
    "existing_files = read_data('/home/ubuntu/Static')\n",
    "existingfilenames_df = pd.DataFrame(np.array(existing_files).reshape(len(existing_files),1), columns = ['apk'])\n",
    "existingfilenames_df.head()\n",
    "fileswithlabel = pd.read_csv(\"/home/ubuntu/labelledfileswith-txt.txt\")\n",
    "fileswithlabel.head()\n",
    "fileslistwithlabel = existingfilenames_df.set_index('apk').join(fileswithlabel.set_index('apk'))\n",
    "del existingfilenames_df\n",
    "fileslistwithlabel.reset_index(inplace=True)\n",
    "del fileswithlabel\n",
    "fileslistwithlabel.head()\n",
    "fileslistwithlabel['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apk</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD0AC844EBAB732056C7B0FDB7A286DD5279047DBC8FA2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7e1efb3c6fbf513e43e2444cc1ffd322.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AB78EFF2D53026C096B0E6E92EE039BB62A27537D30D6E...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12994c43fcd01e1a1d1b370101ab5c5a.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AE1562D977AC2811266ACDDDE2D846CE61BC37E5ECBCA5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 apk  label\n",
       "0  AD0AC844EBAB732056C7B0FDB7A286DD5279047DBC8FA2...      0\n",
       "1               7e1efb3c6fbf513e43e2444cc1ffd322.txt      1\n",
       "2  AB78EFF2D53026C096B0E6E92EE039BB62A27537D30D6E...      0\n",
       "3               12994c43fcd01e1a1d1b370101ab5c5a.txt      1\n",
       "4  AE1562D977AC2811266ACDDDE2D846CE61BC37E5ECBCA5...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_strat_test_set = pd.read_csv(\"/home/ubuntu/test.csv\")\n",
    "save_strat_test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TEST(session,split_size=5):\n",
    "    validation_num=0\n",
    "    which_fold=1\n",
    "    X_test = save_strat_test_set['apk']  #training data features; currently just filenames\n",
    "    y_test = save_strat_test_set['label']  #training data label\n",
    "    acc,loss = run_validation_or_test(session,which_fold,X_test,y_test,True)\n",
    "    print(\"Test Accuracy for the fold \"+ str(which_fold) + \" = \"+ str(acc)+\" loss = \"+str(loss))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=300\n",
    "def run_validation_or_test(session,which_fold,X_train,y_train,isTest=False):\n",
    "    batch_accuracy=[]\n",
    "    batch_loss=[]\n",
    "    total_batch = int(len(X_train)/batch_size)\n",
    "    #total_batch=1\n",
    "    for i in range (total_batch):\n",
    "        batch_x = X_train[i*batch_size:(i+1)*batch_size]\n",
    "        batch_y = y_train[i*batch_size:(i+1)*batch_size]\n",
    "        #now we have the relevant filenames only\n",
    "        batch_y = make_label(batch_y)\n",
    "        sentences, _ = read_data(\"/home/ubuntu/Static/\",batch_x)\n",
    "        #print(\"read data\")\n",
    "        #nwo we need to convert sentences to word-embedded features and then we are ready to train\n",
    "        batch_x = get_embedding(sentences)\n",
    "        #print(\"got embedding\")\n",
    "        # Reshape data to get 28 seq of 28 elements\n",
    "        batch_x = batch_x.reshape((batch_size,timesteps,num_input))\n",
    "        # Run optimization op (backprop)\n",
    "        loss,acc = session.run([loss_op,accuracy],feed_dict={xin: batch_x,Y: batch_y})\n",
    "        print(\"Accuracy-acc = \" +str(acc) + \"benign  = \"+str(batch_y[:,0].sum()) + \"  malicious = \"+str(batch_y[:,1].sum()))\n",
    "        batch_accuracy.append(acc)\n",
    "        batch_loss.append(loss)\n",
    "        \n",
    "        if isTest==True:\n",
    "            pred_out=tf.argmax(prediction,1)\n",
    "            arr = session.run(pred_out,feed_dict={xin: batch_x, Y: batch_y,learning_rate: 0.01})\n",
    "            newarr = arr.tolist()\n",
    "            from sklearn.metrics import confusion_matrix\n",
    "            #print(batch_y[:10])\n",
    "            #print(newarr[:10])\n",
    "            one_dtestlabel= []\n",
    "            for item in batch_y:\n",
    "                if item[0]==0:\n",
    "                    one_dtestlabel.append(1)\n",
    "                else:\n",
    "                    one_dtestlabel.append(0)\n",
    "            cmatrix = confusion_matrix(one_dtestlabel,newarr)\n",
    "            import matplotlib.pyplot as plt\n",
    "            import itertools\n",
    "            plt.figure()\n",
    "            plot_confusion_matrix(cmatrix, classes=['Benign','Malicious'],title='Confusion matrix')\n",
    "            figname = \"test-Cmatrix\"+str(i)+\".png\"\n",
    "            plt.savefig(figname)\n",
    "    return np.mean(batch_accuracy), np.mean(batch_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(foldername,fileslist):\n",
    "    sentences=[]\n",
    "    numwords=[]\n",
    "    for fname in fileslist:\n",
    "        with open(os.path.join(foldername, fname)) as f:\n",
    "            content = f.read().strip()\n",
    "            content = re.sub(r\"[\\n#]\",\"\",content).split(\" \")\n",
    "            counter = len(content)\n",
    "            numwords.append(counter)   #only consider the 4000 APIs# talk and decide later// part of tuning\n",
    "        sentences.append(content[:4000])\n",
    "        \n",
    "    return sentences,numwords\n",
    "\n",
    "def make_label(val):\n",
    "    \n",
    "    d = np.zeros((val.size,2))\n",
    "    i = 0;\n",
    "    for item in val:\n",
    "        if item==0: #if benign\n",
    "            d[i][0]=1.0\n",
    "        else:\n",
    "            d[i][1]=1.0\n",
    "        i+=1\n",
    "    return d\n",
    "def get_embedding(sentences):\n",
    "    d = np.zeros((len(sentences),4000,100))\n",
    "    i=0\n",
    "    for sentence in sentences:\n",
    "        j=0\n",
    "        for word in sentence:\n",
    "            d[i][j]= model.wv[word]\n",
    "            j+=1\n",
    "        i+=1\n",
    "    return d\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load(\"/home/ubuntu/model-all-100dim-cbag.kv\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_steps = 500\n",
    "              #means there are 84 batches in an epoch with each batch having 150 apps \n",
    "total_epochs = 20\n",
    "display_step = 200\n",
    "# Network Parameters\n",
    "num_input = 100 # MNIST data input (img shape: 28*28)\n",
    "timesteps = 4000 # timesteps\n",
    "num_hidden = 128 # hidden layer num of features\n",
    "num_classes = 2 # Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/ubuntu/Newmodel_3\n"
     ]
    }
   ],
   "source": [
    "sess1=tf.Session() \n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "weights = tf.Variable(tf.random_normal([num_hidden, num_classes]), dtype=tf.float32, name=\"weights\")\n",
    "bias = tf.Variable(tf.random_normal([num_classes]), dtype=tf.float32, name=\"bias\")\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess1.run(init_op)\n",
    "#First let's load meta graph and restore weights\n",
    "saver = tf.train.import_meta_graph('/home/ubuntu/Newmodel_3.meta')\n",
    "saver.restore(sess1,tf.train.latest_checkpoint('./'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xin = graph.get_tensor_by_name(\"placeholders/place_xin:0\")\n",
    "Y = graph.get_tensor_by_name(\"placeholders/place_y:0\")\n",
    "learning_rate = graph.get_tensor_by_name(\"place_learning:0\")\n",
    " \n",
    "#Now, access the op that you want to run. \n",
    "accuracy = graph.get_tensor_by_name(\"Accuracy/op_accuracy:0\")\n",
    "correct_pred = graph.get_tensor_by_name(\"evaluation/op_correct_pred:0\")\n",
    "loss_op = graph.get_tensor_by_name(\"Lossmeasure/op_loss:0\")\n",
    "prediction = graph.get_tensor_by_name(\"Softmax/op_prediction:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.global_variables()\n",
    "#All_varaibles = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:31: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy-acc = 0.9633333benign  = 221.0  malicious = 79.0\n",
      "Confusion matrix, without normalization\n",
      "[[218   3]\n",
      " [  8  71]]\n",
      "Accuracy-acc = 0.96benign  = 233.0  malicious = 67.0\n",
      "Confusion matrix, without normalization\n",
      "[[228   5]\n",
      " [  7  60]]\n",
      "Accuracy-acc = 0.9633333benign  = 233.0  malicious = 67.0\n",
      "Confusion matrix, without normalization\n",
      "[[227   6]\n",
      " [  5  62]]\n",
      "Accuracy-acc = 0.99benign  = 222.0  malicious = 78.0\n",
      "Confusion matrix, without normalization\n",
      "[[220   2]\n",
      " [  1  77]]\n",
      "Accuracy-acc = 0.95666665benign  = 221.0  malicious = 79.0\n"
     ]
    }
   ],
   "source": [
    "TEST(sess1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
