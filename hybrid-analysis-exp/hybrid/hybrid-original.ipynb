{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Embedding,Dense,Flatten\n",
    "#from keras.models import load_model\n",
    "import numpy as np\n",
    "import os,sys\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict_static={}\n",
    "def create_static_label():\n",
    "    \n",
    "    with open(\"/home/ubuntu/composite.txt\") as file:\n",
    "        for _ in range(18227):\n",
    "            line  = file.readline().strip().split(\",\")\n",
    "            label_dict_static[line[0]] = line[1]\n",
    "create_static_label()\n",
    "\n",
    "label_dict_dynamic={}\n",
    "def create_dynamic_label():\n",
    "    \n",
    "    with open(\"/home/ubuntu/composite_dynamic.txt\") as file:\n",
    "        for _ in range(18227):\n",
    "            line  = file.readline().strip().split(\",\")\n",
    "            label_dict_dynamic[line[0]] = line[1]\n",
    "create_dynamic_label()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model_static = KeyedVectors.load(\"/home/ubuntu/first.model\", mmap='r')\n",
    "word2vec_model_dynamic = KeyedVectors.load(\"/home/ubuntu/dynamic_word.model\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#nb_words=len(word2vec_model.wv.vocab), will be parameter for tokenizer\n",
    "tokenizer = Tokenizer(filters='#\\n')\n",
    "tokenizer.fit_on_texts(word2vec_model_static.wv.vocab.keys())\n",
    "word_index = tokenizer.word_index\n",
    "temp_array=[]\n",
    "validation_size = 50\n",
    "def get_validation_data(file_names):\n",
    "    c=0 \n",
    "    temp_array=[]\n",
    "    \n",
    "    while True:\n",
    "        if c>=len(file_names):\n",
    "            c=0\n",
    "        for i,j in enumerate(file_names[c:c+validation_size]):\n",
    "            l = open(\"/home/ubuntu/static_validation/\"+j,'r').read().strip()\n",
    "            padded_sequence =  sequence.pad_sequences(tokenizer.texts_to_sequences([l]),maxlen=4000,padding='post',truncating='post')\n",
    "            temp_array.append(padded_sequence[0])\n",
    "            \n",
    "\n",
    "        temp_array = np.array(temp_array)\n",
    "        #label_array = np.array(label_array)\n",
    "        #temp_array = temp_array[..., np.newaxis]\n",
    "        #print(\"\\nYIELDING FROM c = \",c,\" c+validation_size = \",c+validation_size,\" and length of temp_array = \",len(temp_array))\n",
    "        yield (temp_array)\n",
    "        temp_array=[]\n",
    "        c+=validation_size\n",
    "list_of_validation_files = os.listdir(\"/home/ubuntu/static_validation\")\n",
    "#print(list_of_validation_files)\n",
    "list_of_validation_files.sort()\n",
    "validation_generator = get_validation_data(list_of_validation_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2738: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:168: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:175: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "static_model=load_model(\"/home/ubuntu/static-keras/lstm_model-final-mask_zero.h5\")\n",
    "dynamic_model = load_model(\"/home/ubuntu/dynamic-keras/final-dynamic_lstm_model-maskZero.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_static = static_model.predict_generator(validation_generator,math.ceil(len(list_of_validation_files)/validation_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(filters='#\\n')\n",
    "tokenizer.fit_on_texts(word2vec_model_dynamic.wv.vocab.keys())\n",
    "word_index = tokenizer.word_index\n",
    "temp_array=[]\n",
    "validation_size = 50\n",
    "def get_validation_data(file_names):\n",
    "    c=0 \n",
    "    temp_array=[]\n",
    "    \n",
    "    while True:\n",
    "        if c>=len(file_names):\n",
    "            c=0\n",
    "        for i,j in enumerate(file_names[c:c+validation_size]):\n",
    "            l = open(\"/home/ubuntu/dynamic_validation/\"+j,'r').read().strip()\n",
    "            padded_sequence =  sequence.pad_sequences(tokenizer.texts_to_sequences([l]),maxlen=4000,padding='post',truncating='post')\n",
    "            temp_array.append(padded_sequence[0])\n",
    "            \n",
    "\n",
    "        temp_array = np.array(temp_array)\n",
    "        #label_array = np.array(label_array)\n",
    "        #temp_array = temp_array[..., np.newaxis]\n",
    "        #print(\"\\nYIELDING FROM c = \",c,\" c+validation_size = \",c+validation_size,\" and length of temp_array = \",len(temp_array))\n",
    "        yield (temp_array)\n",
    "        \n",
    "        temp_array=[]\n",
    "        c+=validation_size\n",
    "list_of_validation_files = os.listdir(\"/home/ubuntu/dynamic_validation\")\n",
    "#print(list_of_validation_files)\n",
    "list_of_validation_files.sort()\n",
    "validation_generator = get_validation_data(list_of_validation_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dynamic = dynamic_model.predict_generator(validation_generator,math.ceil(len(list_of_validation_files)/validation_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.clf()\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",verticalalignment=\"top\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Confusion-Matrix-Hybrid.png')\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01085447 0.9891455 ]\n",
      " [0.00115068 0.99884933]\n",
      " [0.00644273 0.99355733]]\n",
      "[[2.1644326e-05 9.9997830e-01]\n",
      " [4.4914414e-05 9.9995506e-01]\n",
      " [2.9856481e-05 9.9997020e-01]]\n",
      "[[0.02168729 0.97831273]\n",
      " [0.00225645 0.9977436 ]\n",
      " [0.01285561 0.9871444 ]]\n",
      "[1 1 1 ... 1 1 0]\n",
      "Confusion matrix, without normalization\n",
      "[[1997    3]\n",
      " [  24  976]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "actual_labels=[]\n",
    "for i,j in enumerate(list_of_validation_files):\n",
    "    if int(label_dict_dynamic.get(j))==1:\n",
    "                actual_labels.append(1)\n",
    "    else:\n",
    "                actual_labels.append(0)\n",
    "#print(actual_labels)\n",
    "#print(prediction)\n",
    "prediction = (prediction_dynamic+prediction_static)/2\n",
    "print(prediction[:3])\n",
    "print(prediction_dynamic[:3])\n",
    "print(prediction_static[:3])\n",
    "prediction1 = np.argmax(prediction, axis=1) \n",
    "print(prediction1)\n",
    "\n",
    "cm = confusion_matrix(actual_labels, prediction1)\n",
    "plot_confusion_matrix(cm,['benign','malicious'],title='CONFUSION MATRIX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under graph 0.9978915902538458\n",
      "-------------------------------------------------\n",
      "Precision for Malicious apps 0.9969356486210419\n",
      "Recall for Malicious apps 0.976\n",
      "F1-score for Malicious apps  0.9863567458312279\n",
      "-------------------------------------------------\n",
      "Precision for Benign apps 0.9881246907471549\n",
      "Recall for Benign apps 0.9985\n",
      "F1-score for Benign apps  0.99328525242477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "from funcsigs import signature\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "from inspect import signature\n",
    "\n",
    "def call_precision_recall_curve(truelabel,predictedlabel,actualprediction,label):\n",
    "    \n",
    "    #print(truelabel.shape)\n",
    "    #print(actualprediction.shape)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(truelabel,actualprediction)\n",
    "    au = auc(recall, precision)\n",
    "    print(\"Area under graph \"+str(au))\n",
    "    print(\"-------------------------------------------------\")\n",
    "    rec_score = recall_score(truelabel,predictedlabel,pos_label=1,average='binary')\n",
    "    precise_score = precision_score(truelabel,predictedlabel,pos_label=1,average='binary')\n",
    "    f1 = f1_score(truelabel,predictedlabel,pos_label=1, average='binary')\n",
    "    print(\"Precision for Malicious apps \"+str(precise_score))\n",
    "    print(\"Recall for Malicious apps \"+str(rec_score))\n",
    "    print(\"F1-score for Malicious apps  \" + str(f1))\n",
    "    print(\"-------------------------------------------------\")\n",
    "    rec_score = recall_score(truelabel,predictedlabel,pos_label=0,average='binary')\n",
    "    precise_score = precision_score(truelabel,predictedlabel,pos_label=0,average='binary')\n",
    "    f1 = f1_score(truelabel,predictedlabel,pos_label=0, average='binary')\n",
    "    print(\"Precision for Benign apps \"+str(precise_score))\n",
    "    print(\"Recall for Benign apps \"+str(rec_score))\n",
    "    print(\"F1-score for Benign apps  \" + str(f1))\n",
    "    \n",
    "    \n",
    "    #plot the no-skill line too\n",
    "    positive_cases = sum(truelabel)/len(truelabel)\n",
    "    plt.plot([0, 1], [positive_cases, positive_cases], linestyle='--')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "    step_kwargs = ({'step': 'post'}\n",
    "                   if 'step' in signature(plt.fill_between).parameters\n",
    "                   else {})\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall curve')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Precision-Recall-Curve-Hybrid.png')\n",
    "    plt.clf()\n",
    "prediction_for_1=[]\n",
    "for each_prediction in prediction:\n",
    "    prediction_for_1.append(each_prediction[1])\n",
    "call_precision_recall_curve(np.array(actual_labels),np.array(prediction1),np.array(prediction_for_1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
