{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Embedding,Dense,Flatten\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from keras.models import load_model\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import os,sys\n",
    "import math\n",
    "input_path = \"/home/ubuntu/static_mixed\"\n",
    "word2vec_model = KeyedVectors.load(\"/home/ubuntu/first.model\", mmap='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict={}\n",
    "def create_label():\n",
    "    \n",
    "    with open(\"/home/ubuntu/composite.txt\") as file:\n",
    "        for _ in range(18227):\n",
    "            line  = file.readline().strip().split(\",\")\n",
    "            label_dict[line[0]] = line[1]\n",
    "create_label()\n",
    "\n",
    "#print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#HERE START GENERATOR THINGY\n",
    "import os\n",
    "import random\n",
    "#nb_words=len(word2vec_model.wv.vocab), will be parameter for tokenizer\n",
    "tokenizer = Tokenizer(filters='#\\n')\n",
    "tokenizer.fit_on_texts(word2vec_model.wv.vocab.keys())\n",
    "word_index = tokenizer.word_index\n",
    "temp_array=[]\n",
    "batch_size = 75\n",
    "def get_content(file_names,train_indices):\n",
    "    c=0 \n",
    "    temp_array=[]\n",
    "    label_array=[]\n",
    "    while True:\n",
    "        if c>=len(train_indices):\n",
    "            c=0\n",
    "        for i,j in enumerate(train_indices[c:c+batch_size]):\n",
    "            l = open(\"/home/ubuntu/static_mixed/\"+file_names[j],'r').read().strip()\n",
    " \n",
    "            padded_sequence =  sequence.pad_sequences(tokenizer.texts_to_sequences([l]),maxlen=4000, padding='post',truncating='post')\n",
    "\n",
    "            temp_array.append(padded_sequence[0])\n",
    "            if int(label_dict.get(file_names[j]))==1:\n",
    "                label_array.append([0,1])\n",
    "            else:\n",
    "                label_array.append([1,0])\n",
    "\n",
    "        temp_array = np.array(temp_array)\n",
    "        label_array = np.array(label_array)\n",
    "        #print(\"\\nYIELDING FROM c = \",c,\" c+batch_size = \",c+batch_size,\" and length of temp_array = \",len(temp_array),len(label_array))\n",
    "        yield (temp_array, label_array)\n",
    "        label_array=[]\n",
    "        temp_array=[]\n",
    "        c+=batch_size\n",
    "#files_ = os.listdir(\"/home/ubuntu/static_mixed\")\n",
    "#random.shuffle(files_)\n",
    "#train_data = get_content(files_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VALidation generator\n",
    "\n",
    "validation_size = 50\n",
    "def get_validation_data(file_names,validation_indices):\n",
    "    c=0 \n",
    "    temp_array=[]\n",
    "    \n",
    "    while True:\n",
    "        if c>=len(validation_indices):\n",
    "            c=0\n",
    "        for i,j in enumerate(validation_indices[c:c+validation_size]):\n",
    "            l = open(\"/home/ubuntu/static_mixed/\"+file_names[j],'r').read().strip()\n",
    "            padded_sequence =  sequence.pad_sequences(tokenizer.texts_to_sequences([l]),maxlen=4000,padding='post',truncating='post')\n",
    "            temp_array.append(padded_sequence[0])\n",
    "            \n",
    "\n",
    "        temp_array = np.array(temp_array)\n",
    "        yield (temp_array)\n",
    "        \n",
    "        temp_array=[]\n",
    "        c+=validation_size\n",
    "# list_of_validation_files = os.listdir(\"/home/ubuntu/static_validation\")\n",
    "# #print(list_of_validation_files)\n",
    "# validation_generator = get_validation_data(list_of_validation_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(word2vec_model.wv.vocab)+1,100))\n",
    "for word, i in word_index.items():\n",
    "    embedding_matrix[i]=word2vec_model.wv[word]\n",
    "\n",
    "def get_model(learning_rate,hidden_units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(word2vec_model.wv.vocab)+1,100,weights=[embedding_matrix],input_length=4000))\n",
    "    model.add(LSTM(hidden_units,return_sequences=False))\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    model.layers[0].trainable = False\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=learning_rate),metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=load_model(\"lstm_model.h5\")\n",
    "# model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.01),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "def plot_confusion_matrix(counter,cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",verticalalignment=\"top\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Confusion-Matrix-'+str(counter)+'.png')\n",
    "    plt.tight_layout()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "from funcsigs import signature\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "from inspect import signature\n",
    "\n",
    "def call_precision_recall_curve(counter,truelabel,predictedlabel,actualprediction,label):\n",
    "    \n",
    "    #print(truelabel.shape)\n",
    "    #print(actualprediction.shape)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(truelabel,actualprediction)\n",
    "    au = auc(recall, precision)\n",
    "    print(\"Area under graph \"+str(au))\n",
    "    print(\"-------------------------------------------------\")\n",
    "    rec_score = recall_score(truelabel,predictedlabel,pos_label=1,average='binary')\n",
    "    precise_score = precision_score(truelabel,predictedlabel,pos_label=1,average='binary')\n",
    "    f1 = f1_score(truelabel,predictedlabel,pos_label=1, average='binary')\n",
    "    print(\"Precision for Malicious apps \"+str(precise_score))\n",
    "    print(\"Recall for Malicious apps \"+str(rec_score))\n",
    "    print(\"F1-score for Malicious apps  \" + str(f1))\n",
    "    print(\"-------------------------------------------------\")\n",
    "    rec_score = recall_score(truelabel,predictedlabel,pos_label=0,average='binary')\n",
    "    precise_score = precision_score(truelabel,predictedlabel,pos_label=0,average='binary')\n",
    "    f1 = f1_score(truelabel,predictedlabel,pos_label=0, average='binary')\n",
    "    print(\"Precision for Benign apps \"+str(precise_score))\n",
    "    print(\"Recall for Benign apps \"+str(rec_score))\n",
    "    print(\"F1-score for Benign apps  \" + str(f1))\n",
    "    \n",
    "    \n",
    "    #plot the no-skill line too\n",
    "    positive_cases = sum(truelabel)/len(truelabel)\n",
    "    plt.plot([0, 1], [positive_cases, positive_cases], linestyle='--')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "    step_kwargs = ({'step': 'post'}\n",
    "                   if 'step' in signature(plt.fill_between).parameters\n",
    "                   else {})\n",
    "    plt.step(recall, precision, color='b', alpha=0.2,\n",
    "             where='post')\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall curve')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('Precision-Recall-Curve-'+str(counter)+'.png')\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03333cf556291927c5f386415b154f59.txt 0ba28c10b8c36ab399990d7b54ffd8f6.txt\n"
     ]
    }
   ],
   "source": [
    "labels_skf = []\n",
    "files_ = os.listdir(input_path)\n",
    "files_.sort()\n",
    "for i,j in enumerate(files_):\n",
    "    if int(label_dict.get(j))==1:\n",
    "                labels_skf.append(1)\n",
    "    else:\n",
    "                labels_skf.append(0)\n",
    "len(labels_skf)\n",
    "print(files_[100],files_[332])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_actual_labels(file_names,validation_indices):\n",
    "    actual_labels=[]\n",
    "    for i,j in enumerate(validation_indices):\n",
    "        if int(label_dict.get(file_names[j]))==1:\n",
    "                    actual_labels.append(1)\n",
    "        else:\n",
    "                    actual_labels.append(0)\n",
    "    return actual_labels\n",
    "#print(actual_labels)\n",
    "#print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 12942 TEST: 2285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 4000, 100)         9848200   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 9,965,706\n",
      "Trainable params: 117,506\n",
      "Non-trainable params: 9,848,200\n",
      "_________________________________________________________________\n",
      "Epoch 1/7\n",
      "173/173 [==============================] - 807s 5s/step - loss: 0.5130 - acc: 0.7411\n",
      "Epoch 2/7\n",
      "173/173 [==============================] - 807s 5s/step - loss: 0.2338 - acc: 0.9119\n",
      "Epoch 3/7\n",
      "173/173 [==============================] - 809s 5s/step - loss: 0.1604 - acc: 0.9429\n",
      "Epoch 4/7\n",
      "173/173 [==============================] - 807s 5s/step - loss: 0.1306 - acc: 0.9551\n",
      "Epoch 5/7\n",
      "173/173 [==============================] - 808s 5s/step - loss: 0.1506 - acc: 0.9485\n",
      "Epoch 6/7\n",
      "173/173 [==============================] - 811s 5s/step - loss: 0.1439 - acc: 0.9465\n",
      "Epoch 7/7\n",
      "173/173 [==============================] - 813s 5s/step - loss: 0.0967 - acc: 0.9685\n",
      "TRAINING for FOLD  1  Finished\n",
      "Model_saved\n",
      "[0 0 0 ... 0 0 0]\n",
      "Confusion matrix, without normalization\n",
      "[[1566   26]\n",
      " [  91  602]]\n",
      "Area under graph 0.9654410438109963\n",
      "-------------------------------------------------\n",
      "Precision for Malicious apps 0.9585987261146497\n",
      "Recall for Malicious apps 0.8686868686868687\n",
      "F1-score for Malicious apps  0.9114307342922028\n",
      "-------------------------------------------------\n",
      "Precision for Benign apps 0.9450814725407363\n",
      "Recall for Benign apps 0.9836683417085427\n",
      "F1-score for Benign apps  0.96398891966759\n",
      "ITERATION  1  FINISHED\n",
      "TRAIN: 12942 TEST: 2285\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 4000, 100)         9848200   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 9,965,706\n",
      "Trainable params: 117,506\n",
      "Non-trainable params: 9,848,200\n",
      "_________________________________________________________________\n",
      "Epoch 1/7\n",
      "173/173 [==============================] - 825s 5s/step - loss: 0.5438 - acc: 0.7078\n",
      "Epoch 2/7\n",
      "173/173 [==============================] - 827s 5s/step - loss: 0.4922 - acc: 0.7615\n",
      "Epoch 3/7\n",
      "173/173 [==============================] - 825s 5s/step - loss: 0.4276 - acc: 0.8133\n",
      "Epoch 4/7\n",
      "173/173 [==============================] - 823s 5s/step - loss: 0.3882 - acc: 0.8397\n",
      "Epoch 5/7\n",
      "173/173 [==============================] - 827s 5s/step - loss: 0.4519 - acc: 0.7832\n",
      "Epoch 6/7\n",
      "173/173 [==============================] - 819s 5s/step - loss: 0.5121 - acc: 0.7173\n",
      "Epoch 7/7\n",
      "173/173 [==============================] - 822s 5s/step - loss: 0.4822 - acc: 0.7263\n",
      "TRAINING for FOLD  2  Finished\n",
      "Model_saved\n",
      "[0 0 0 ... 0 0 0]\n",
      "Confusion matrix, without normalization\n",
      "[[1586    6]\n",
      " [ 617   76]]\n",
      "Area under graph 0.6745015606967384\n",
      "-------------------------------------------------\n",
      "Precision for Malicious apps 0.926829268292683\n",
      "Recall for Malicious apps 0.10966810966810966\n",
      "F1-score for Malicious apps  0.19612903225806452\n",
      "-------------------------------------------------\n",
      "Precision for Benign apps 0.7199273717657739\n",
      "Recall for Benign apps 0.9962311557788944\n",
      "F1-score for Benign apps  0.835836627140975\n",
      "ITERATION  2  FINISHED\n",
      "TRAIN: 12942 TEST: 2285\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 4000, 100)         9848200   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 9,965,706\n",
      "Trainable params: 117,506\n",
      "Non-trainable params: 9,848,200\n",
      "_________________________________________________________________\n",
      "Epoch 1/7\n",
      "173/173 [==============================] - 813s 5s/step - loss: 0.5861 - acc: 0.6929\n",
      "Epoch 2/7\n",
      "173/173 [==============================] - 813s 5s/step - loss: 0.5473 - acc: 0.7060\n",
      "Epoch 3/7\n",
      "173/173 [==============================] - 813s 5s/step - loss: 0.5280 - acc: 0.7129\n",
      "Epoch 4/7\n",
      "173/173 [==============================] - 813s 5s/step - loss: 0.5123 - acc: 0.7198\n",
      "Epoch 5/7\n",
      "173/173 [==============================] - 815s 5s/step - loss: 0.4999 - acc: 0.7240\n",
      "Epoch 6/7\n",
      "173/173 [==============================] - 815s 5s/step - loss: 0.4904 - acc: 0.7293\n",
      "Epoch 7/7\n",
      "173/173 [==============================] - 810s 5s/step - loss: 0.4821 - acc: 0.7316\n",
      "TRAINING for FOLD  3  Finished\n",
      "Model_saved\n",
      "[1 0 0 ... 0 0 0]\n",
      "Confusion matrix, without normalization\n",
      "[[1570   22]\n",
      " [ 615   78]]\n",
      "Area under graph 0.6016979001719414\n",
      "-------------------------------------------------\n",
      "Precision for Malicious apps 0.78\n",
      "Recall for Malicious apps 0.11255411255411256\n",
      "F1-score for Malicious apps  0.19672131147540986\n",
      "-------------------------------------------------\n",
      "Precision for Benign apps 0.7185354691075515\n",
      "Recall for Benign apps 0.9861809045226131\n",
      "F1-score for Benign apps  0.8313476303944931\n",
      "ITERATION  3  FINISHED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skf = StratifiedShuffleSplit(n_splits=3, test_size=0.15, random_state=0)\n",
    "learning_rates= [0.01,0.001,0.0001]\n",
    "hidden_units = [128,128,128]\n",
    "counter = 0\n",
    "for train_indices, test_indices in skf.split(files_, labels_skf):\n",
    "    print(\"TRAIN:\", len(train_indices), \"TEST:\", len(test_indices))\n",
    "    train_data = get_content(files_,train_indices)\n",
    "    model = get_model(learning_rates[counter],hidden_units[counter])\n",
    "    steps_per_epoch = math.ceil(len(train_indices)/batch_size)\n",
    "    #steps_per_epoch =1\n",
    "    model.fit_generator(train_data,epochs=7,steps_per_epoch=steps_per_epoch)\n",
    "    print(\"TRAINING for FOLD \",counter+1,\" Finished\")\n",
    "    model.save('lstm_model_validation_'+str(counter)+\".h5\")\n",
    "    print('Model_saved')\n",
    "    validation_generator = get_validation_data(files_,test_indices)\n",
    "    prediction = model.predict_generator(validation_generator,math.ceil(len(test_indices)/validation_size))\n",
    "    prediction1 = np.argmax(prediction, axis=1) \n",
    "    print(prediction1)\n",
    "    actual_labels = create_actual_labels(files_,test_indices)\n",
    "    cm = confusion_matrix(actual_labels, prediction1)\n",
    "    plot_confusion_matrix(counter,cm,['benign','malicious'],title='CONFUSION MATRIX')\n",
    "    prediction_for_1=[]\n",
    "    for each_prediction in prediction:\n",
    "        prediction_for_1.append(each_prediction[1])\n",
    "    call_precision_recall_curve(counter,np.array(actual_labels),np.array(prediction1),np.array(prediction_for_1),1)\n",
    "    counter+=1\n",
    "    print('ITERATION ',counter,' FINISHED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14]] [0, 1, 0, 1, 0, 1, 0]\n",
      "TRAIN: [6 1 5 4 2] TEST: [3 0]\n",
      "[13, 14]\n",
      "[3, 4]\n",
      "[11, 12]\n",
      "[9, 10]\n",
      "[5, 6]\n",
      "[[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14]] [0, 1, 0, 1, 0, 1, 0]\n",
      "TRAIN: [3 4 1 2 6] TEST: [0 5]\n",
      "[7, 8]\n",
      "[9, 10]\n",
      "[3, 4]\n",
      "[5, 6]\n",
      "[13, 14]\n",
      "[[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13, 14]] [0, 1, 0, 1, 0, 1, 0]\n",
      "TRAIN: [5 6 3 2 4] TEST: [0 1]\n",
      "[11, 12]\n",
      "[13, 14]\n",
      "[7, 8]\n",
      "[5, 6]\n",
      "[9, 10]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18227 18227\n",
      "TRAIN: [6076 6077 6078 6079 6080 6081 6082 6083] TEST: [0 1 2 3 4 5 6 7]\n",
      "TRAIN: [0 1 2 3 4 5 6 7] TEST: [6076 6077 6078 6079 6080 6081 6082 6083]\n",
      "TRAIN: [0 1 2 3 4 5 6 7] TEST: [12152 12153 12154 12155 12156 12157 12158 12159]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
